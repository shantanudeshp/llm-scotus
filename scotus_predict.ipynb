{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanudeshp/llm-scotus/blob/20230904-wip/scotus_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c935d2",
      "metadata": {
        "id": "d5c935d2"
      },
      "outputs": [],
      "source": [
        "# Use case_data to get case details, and call the openai llm models to predict outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287d784d",
      "metadata": {
        "id": "287d784d",
        "outputId": "bbcc9d3d-3a0f-494d-a060-60212d0b5991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foo\n"
          ]
        }
      ],
      "source": [
        "%run case_data.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed7f8cc",
      "metadata": {
        "collapsed": true,
        "id": "0ed7f8cc",
        "outputId": "e3b52f75-6b2b-42f9-f7b7-1916e7f3dde7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f202ea52",
      "metadata": {
        "id": "f202ea52"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f7d8e2",
      "metadata": {
        "id": "d7f7d8e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import openai\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bed038a",
      "metadata": {
        "id": "0bed038a",
        "outputId": "772e81ee-ef1c-461f-afc4-e54292411c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the openai key··········\n"
          ]
        }
      ],
      "source": [
        "openai_key = getpass('Enter the openai key')\n",
        "#openai_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c9e720e",
      "metadata": {
        "id": "0c9e720e"
      },
      "outputs": [],
      "source": [
        "openai.organization = \"org-YjWOHW4W2uUvobjJfFBOBkU8\"\n",
        "openai.api_key = openai_key\n",
        "#openai.Model.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00998f08",
      "metadata": {
        "id": "00998f08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd90037",
      "metadata": {
        "id": "2bd90037"
      },
      "outputs": [],
      "source": [
        "instructions = '''The following is a brief outline of a case. Predict the verdict of the Supreme Court by responding with the name of the Contestant they would most likely side with.\n",
        "For example:\n",
        "If the contestants are Reagan v. Alabama, respond with either Reagan or Alabama.\n",
        "If the contestants are Lubkowitz v. Smith, respond with either Lubkowitz or Smith.\n",
        "If the contestants are Department of Defense v. Higgins, respond with either Department of Defense or Higgins.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11a5e13",
      "metadata": {
        "id": "c11a5e13",
        "outputId": "a490c4f6-0690-4809-a28c-81d117ee077a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{instructions}\n",
            "\n",
            "Case: {case_name}\n",
            "\n",
            "Summary: {case_summary}\n",
            "\n",
            "Verdict:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "template1 = \"\"\"\n",
        "{instructions}\n",
        "\n",
        "Case: {case_name}\n",
        "\n",
        "Summary: {case_summary}\n",
        "\n",
        "Verdict:\n",
        "\"\"\"\n",
        "\n",
        "print(template1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a05a9a",
      "metadata": {
        "id": "47a05a9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd8d844",
      "metadata": {
        "id": "8fd8d844"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, engine=\"text-davinci-003\", max_tokens=100):\n",
        "    response = openai.Completion.create(\n",
        "        engine=engine,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    tokens_used = response.usage['total_tokens']\n",
        "    return response.choices[0].text.strip(), tokens_used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "babac73c",
      "metadata": {
        "id": "babac73c"
      },
      "outputs": [],
      "source": [
        "def get_verdict(url, engine=\"text-davinci-003\"):\n",
        "    case_details = get_case_details(url)\n",
        "    # 1. Call the scrape_contestants and scrape_syllabus functions on each URL\n",
        "    case_name = case_details['contestants']\n",
        "    case_summary = case_details['syllabus']\n",
        "    #TODO: check both are not None\n",
        "\n",
        "    # 2. Put the outputs inside the template\n",
        "    prompt = template1.format(instructions=instructions, case_name=case_name, case_summary=case_summary)\n",
        "\n",
        "    # 3. Call the LLM API to predict the verdict for each\n",
        "    predicted_verdict, tokens_used = generate(prompt, engine)\n",
        "\n",
        "    # 4. Store the verdict and tokens used for each URL\n",
        "    results = {\n",
        "        \"url\": url,\n",
        "        \"predicted_verdict\": predicted_verdict,\n",
        "        \"tokens_used\": tokens_used\n",
        "    }\n",
        "\n",
        "    # 5. Return the results\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c40c841",
      "metadata": {
        "id": "0c40c841"
      },
      "outputs": [],
      "source": [
        "def get_verdicts(urls, engine=\"text-davinci-003\"):\n",
        "    verdicts = [get_verdict(u) for u in urls]\n",
        "    return verdicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c76b32",
      "metadata": {
        "id": "13c76b32",
        "outputId": "462f96e4-0dfe-44d5-ab2f-0e07397313fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://supreme.justia.com/cases/federal/us/597/21-954/, Predicted Verdict: Biden, Tokens used: 1463\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "urls = ['https://supreme.justia.com/cases/federal/us/597/21-954/']  # Add more URLs as needed\n",
        "verdicts = get_verdicts(urls)\n",
        "\n",
        "for verdict in verdicts:\n",
        "    print(f\"URL: {verdict['url']}, Predicted Verdict: {verdict['predicted_verdict']}, Tokens used: {verdict['tokens_used']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08ed78f9",
      "metadata": {
        "id": "08ed78f9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:mr-delta2] *",
      "language": "python",
      "name": "conda-env-mr-delta2-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}